{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1903</td>\n",
       "      <td>The Great Train Robbery</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>western</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Great_Train_...</td>\n",
       "      <td>The film opens with two bandits breaking into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1904</td>\n",
       "      <td>The Suburbanite</td>\n",
       "      <td>American</td>\n",
       "      <td>Wallace McCutcheon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Suburbanite</td>\n",
       "      <td>The film is about a family who move to the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1906</td>\n",
       "      <td>Dream of a Rarebit Fiend</td>\n",
       "      <td>American</td>\n",
       "      <td>Wallace McCutcheon and Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>short</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dream_of_a_Rareb...</td>\n",
       "      <td>The Rarebit Fiend gorges on Welsh rarebit at a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1906</td>\n",
       "      <td>From Leadville to Aspen: A Hold-Up in the Rockies</td>\n",
       "      <td>American</td>\n",
       "      <td>Francis J. Marion and Wallace McCutcheon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>short action/crime western</td>\n",
       "      <td>https://en.wikipedia.org/wiki/From_Leadville_t...</td>\n",
       "      <td>The film features a train traveling through th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1906</td>\n",
       "      <td>Kathleen Mavourneen</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>short film</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kathleen_Mavourn...</td>\n",
       "      <td>Irish villager Kathleen is a tenant of Captain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34877</th>\n",
       "      <td>2013</td>\n",
       "      <td>Particle (film)</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Erdem Tepegöz</td>\n",
       "      <td>Jale Arıkan, Rüçhan Caliskur, Özay Fecht, Remz...</td>\n",
       "      <td>drama film</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Particle_(film)</td>\n",
       "      <td>Zeynep lost her job at weaving factory, and he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34882</th>\n",
       "      <td>2017</td>\n",
       "      <td>Çalgı Çengi İkimiz</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Selçuk Aydemir</td>\n",
       "      <td>Ahmet Kural, Murat Cemcir</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/%C3%87alg%C4%B1_...</td>\n",
       "      <td>Two musicians, Salih and Gürkan, described the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34883</th>\n",
       "      <td>2017</td>\n",
       "      <td>Olanlar Oldu</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Hakan Algül</td>\n",
       "      <td>Ata Demirer, Tuvana Türkay, Ülkü Duru</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Olanlar_Oldu</td>\n",
       "      <td>Zafer, a sailor living with his mother Döndü i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34884</th>\n",
       "      <td>2017</td>\n",
       "      <td>Non-Transferable</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Brendan Bradley</td>\n",
       "      <td>YouTubers Shanna Malcolm, Shira Lazar, Sara Fl...</td>\n",
       "      <td>romantic comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Non-Transferable...</td>\n",
       "      <td>The film centres around a young woman named Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34885</th>\n",
       "      <td>2017</td>\n",
       "      <td>İstanbul Kırmızısı</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Ferzan Özpetek</td>\n",
       "      <td>Halit Ergenç, Tuba Büyüküstün, Mehmet Günsür, ...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>https://en.wikipedia.org/wiki/%C4%B0stanbul_K%...</td>\n",
       "      <td>The writer Orhan Şahin returns to İstanbul aft...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28803 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Release Year                                              Title  \\\n",
       "6              1903                            The Great Train Robbery   \n",
       "7              1904                                    The Suburbanite   \n",
       "10             1906                           Dream of a Rarebit Fiend   \n",
       "11             1906  From Leadville to Aspen: A Hold-Up in the Rockies   \n",
       "12             1906                                Kathleen Mavourneen   \n",
       "...             ...                                                ...   \n",
       "34877          2013                                    Particle (film)   \n",
       "34882          2017                                 Çalgı Çengi İkimiz   \n",
       "34883          2017                                       Olanlar Oldu   \n",
       "34884          2017                                   Non-Transferable   \n",
       "34885          2017                                 İstanbul Kırmızısı   \n",
       "\n",
       "      Origin/Ethnicity                                  Director  \\\n",
       "6             American                           Edwin S. Porter   \n",
       "7             American                        Wallace McCutcheon   \n",
       "10            American    Wallace McCutcheon and Edwin S. Porter   \n",
       "11            American  Francis J. Marion and Wallace McCutcheon   \n",
       "12            American                           Edwin S. Porter   \n",
       "...                ...                                       ...   \n",
       "34877          Turkish                             Erdem Tepegöz   \n",
       "34882          Turkish                            Selçuk Aydemir   \n",
       "34883          Turkish                               Hakan Algül   \n",
       "34884          Turkish                           Brendan Bradley   \n",
       "34885          Turkish                            Ferzan Özpetek   \n",
       "\n",
       "                                                    Cast  \\\n",
       "6                                                    NaN   \n",
       "7                                                    NaN   \n",
       "10                                                   NaN   \n",
       "11                                                   NaN   \n",
       "12                                                   NaN   \n",
       "...                                                  ...   \n",
       "34877  Jale Arıkan, Rüçhan Caliskur, Özay Fecht, Remz...   \n",
       "34882                          Ahmet Kural, Murat Cemcir   \n",
       "34883              Ata Demirer, Tuvana Türkay, Ülkü Duru   \n",
       "34884  YouTubers Shanna Malcolm, Shira Lazar, Sara Fl...   \n",
       "34885  Halit Ergenç, Tuba Büyüküstün, Mehmet Günsür, ...   \n",
       "\n",
       "                            Genre  \\\n",
       "6                         western   \n",
       "7                          comedy   \n",
       "10                          short   \n",
       "11     short action/crime western   \n",
       "12                     short film   \n",
       "...                           ...   \n",
       "34877                  drama film   \n",
       "34882                      comedy   \n",
       "34883                      comedy   \n",
       "34884             romantic comedy   \n",
       "34885                    romantic   \n",
       "\n",
       "                                               Wiki Page  \\\n",
       "6      https://en.wikipedia.org/wiki/The_Great_Train_...   \n",
       "7          https://en.wikipedia.org/wiki/The_Suburbanite   \n",
       "10     https://en.wikipedia.org/wiki/Dream_of_a_Rareb...   \n",
       "11     https://en.wikipedia.org/wiki/From_Leadville_t...   \n",
       "12     https://en.wikipedia.org/wiki/Kathleen_Mavourn...   \n",
       "...                                                  ...   \n",
       "34877      https://en.wikipedia.org/wiki/Particle_(film)   \n",
       "34882  https://en.wikipedia.org/wiki/%C3%87alg%C4%B1_...   \n",
       "34883         https://en.wikipedia.org/wiki/Olanlar_Oldu   \n",
       "34884  https://en.wikipedia.org/wiki/Non-Transferable...   \n",
       "34885  https://en.wikipedia.org/wiki/%C4%B0stanbul_K%...   \n",
       "\n",
       "                                                    Plot  \n",
       "6      The film opens with two bandits breaking into ...  \n",
       "7      The film is about a family who move to the sub...  \n",
       "10     The Rarebit Fiend gorges on Welsh rarebit at a...  \n",
       "11     The film features a train traveling through th...  \n",
       "12     Irish villager Kathleen is a tenant of Captain...  \n",
       "...                                                  ...  \n",
       "34877  Zeynep lost her job at weaving factory, and he...  \n",
       "34882  Two musicians, Salih and Gürkan, described the...  \n",
       "34883  Zafer, a sailor living with his mother Döndü i...  \n",
       "34884  The film centres around a young woman named Am...  \n",
       "34885  The writer Orhan Şahin returns to İstanbul aft...  \n",
       "\n",
       "[28803 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_data_all = pd.read_csv('./data/wiki_movie_plots_deduped.csv')\n",
    "wiki_data_all = wiki_data_all[~wiki_data_all['Genre'].str.contains('unknown')]\n",
    "wiki_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_genre(genre): \n",
    "    return [g.split('(')[0].strip().lower() for g in re.split(',|/', genre) if ')' not in g]\n",
    "    \n",
    "    \n",
    "def filter_plot(plot):\n",
    "    plot = ' '.join(re.split(r'\\[\\d+\\]', plot))\n",
    "    return ' '.join([s.strip(string.punctuation) for s in plot.encode('ascii', 'ignore').decode().split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drama       5964\n",
       "comedy      4379\n",
       "horror      1167\n",
       "action      1098\n",
       "thriller     966\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wiki_data_all['genre_split'] = wiki_data_all['Genre'].apply(filter_genre)\n",
    "\n",
    "wiki_data_select = wiki_data_all[~wiki_data_all['Genre'].str.contains(' ')]\n",
    "top_10_genre = list(wiki_data_select['Genre'].value_counts()[:5].keys())\n",
    "\n",
    "wiki_data_reduced = wiki_data_select[wiki_data_select['Genre'].isin(top_10_genre)].reset_index(drop=True)\n",
    "wiki_data_reduced['plot_filtered'] = wiki_data_reduced['Plot'].apply(filter_plot)\n",
    "wiki_data_reduced['title_filtered'] = wiki_data_reduced['Title'].apply(filter_plot)\n",
    "\n",
    "wiki_data_reduced.Genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9831     Harry England Michael Crawford a British car s...\n",
       " 2814     Mildred Turner is a patient of a New York psyc...\n",
       " 4553     An agent of the United States CIA is arrested ...\n",
       " 7332     In Japanese society it is said a curse is crea...\n",
       " 7989     Following their successful heist in Brazil Dom...\n",
       "                                ...                        \n",
       " 5218     In 2031 Dr Buchanan and his team work to devel...\n",
       " 12252    Cleopatra is an emotional family film which co...\n",
       " 1346     James Cagney plays a truck driver named Danny ...\n",
       " 11646    Krishna is the adopted son of a woman who foun...\n",
       " 3582     Professional racecar driver Frank Capua Paul N...\n",
       " Name: plot_filtered, Length: 9501, dtype: object,\n",
       " 9831     comedy\n",
       " 2814     comedy\n",
       " 4553     comedy\n",
       " 7332     horror\n",
       " 7989     action\n",
       "           ...  \n",
       " 5218     horror\n",
       " 12252     drama\n",
       " 1346      drama\n",
       " 11646    action\n",
       " 3582      drama\n",
       " Name: Genre, Length: 9501, dtype: object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = wiki_data_reduced['plot_filtered']\n",
    "y = wiki_data_reduced['Genre']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=123)\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_count(X_train, X_test, ngram_range=(1,1), stop_words=None, max_features=10000):\n",
    "    count_vect = CountVectorizer(analyzer='word', \n",
    "                                 ngram_range=ngram_range, \n",
    "                                 stop_words=stop_words, \n",
    "                                 max_features=max_features)\n",
    "    \n",
    "    X_train_count_trans = count_vect.fit_transform(X_train)\n",
    "    X_test_count_trans = count_vect.transform(X_test)\n",
    "    \n",
    "    return X_train_count_trans, X_test_count_trans\n",
    "    \n",
    "    \n",
    "def gen_tf(X_train_count_trans, X_test_count_trans):\n",
    "    tf_vect = TfidfTransformer()\n",
    "    \n",
    "    X_train_tf_trans = tf_vect.fit_transform(X_train_count_trans)\n",
    "    X_test_tf_trans = tf_vect.transform(X_test_count_trans)\n",
    "    \n",
    "    return X_train_tf_trans, X_test_tf_trans\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, param_grid):\n",
    "    grid = GridSearchCV(model, param_grid, scoring='balanced_accuracy', n_jobs=-1, verbose=10)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    return grid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count, X_test_count = gen_count(X_train, \n",
    "                                        X_test, \n",
    "                                        ngram_range=(1,1), \n",
    "                                        stop_words=None)\n",
    "X_train_tf, X_test_tf = gen_tf(X_train_count, X_test_count)\n",
    "\n",
    "X_train_count_ngram, X_test_count_ngram = gen_count(X_train, \n",
    "                                                    X_test, \n",
    "                                                    ngram_range=(2,3), \n",
    "                                                    stop_words='english')\n",
    "X_train_tf_ngram, X_test_tf_ngram = gen_tf(X_train_count_ngram, X_test_count_ngram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukev\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan 0.37591004 0.51402566 0.53455664        nan 0.50985727\n",
      " 0.53652562 0.54081244        nan 0.53948022 0.53314352 0.54305069\n",
      "        nan 0.54183923 0.52576747 0.54351406]\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukev\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukev\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan 0.2        0.2        0.2               nan 0.20203776\n",
      " 0.26560879 0.26545925        nan 0.44802309 0.45582085 0.45608783\n",
      "        nan 0.52930424 0.53867437 0.54003059]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukev\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan 0.20015656 0.25277721 0.25464885        nan 0.24257854\n",
      " 0.37345918 0.3758734         nan 0.39320583 0.41341138 0.40982128\n",
      "        nan 0.41422121 0.40527927 0.41356644]\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukev\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukev\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan 0.2        0.2        0.2               nan 0.2\n",
      " 0.21117037 0.21130173        nan 0.29438487 0.31996138 0.32020381\n",
      "        nan 0.40435687 0.39816146 0.39791485]\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukev\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=500)\n",
    "param_grid = {\n",
    "    'penalty':['l1', 'l2'],\n",
    "    'C':[0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'saga']\n",
    "}\n",
    "\n",
    "\n",
    "lr_grid_count = train_model(model, X_train_count, y_train, param_grid)\n",
    "lr_grid_tf = train_model(model, X_train_tf, y_train, param_grid)\n",
    "\n",
    "lr_grid_count_ngram = train_model(model, X_train_count_ngram, y_train, param_grid)\n",
    "lr_grid_tf_ngram = train_model(model, X_train_tf_ngram, y_train, param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 264 candidates, totalling 1320 fits\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('smote', SMOTE(random_state=107)),\n",
    "    ('mb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# param_grid = {\n",
    "#     'count__ngram_range':[(1,2)],\n",
    "#     'count__stop_words':[None, 'english'],\n",
    "#     'count__max_features':[100000],\n",
    "#     'mb__alpha':[round(.1*i, 1) for i in range(11)]\n",
    "# }\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'count__ngram_range':[(1,1), (1,2), (1,3), (1,4)],\n",
    "    'count__stop_words':[None, 'english'],\n",
    "    'count__max_features':[1000, 10000, 100000],\n",
    "    'mb__alpha':[round(.1*i, 1) for i in range(11)]\n",
    "}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, n_jobs=-1, scoring='balanced_accuracy', verbose=100)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action       0.54      0.58      0.56       351\n",
      "      comedy       0.70      0.71      0.70      1334\n",
      "       drama       0.72      0.74      0.73      1754\n",
      "      horror       0.71      0.81      0.75       344\n",
      "    thriller       0.39      0.19      0.26       290\n",
      "\n",
      "    accuracy                           0.68      4073\n",
      "   macro avg       0.61      0.60      0.60      4073\n",
      "weighted avg       0.67      0.68      0.67      4073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid.best_estimator_.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
